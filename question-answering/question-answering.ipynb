{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.kaggle.com/code/putuwidyantara/question-answering\" target=\"_parent\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open In Kaggle\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://huggingface.co/docs/transformers/en/tasks/question_answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T08:11:30.952629Z",
     "iopub.status.busy": "2024-11-29T08:11:30.952335Z",
     "iopub.status.idle": "2024-11-29T08:11:40.789607Z",
     "shell.execute_reply": "2024-11-29T08:11:40.788474Z",
     "shell.execute_reply.started": "2024-11-29T08:11:30.952602Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers datasets evaluate huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T08:11:40.791512Z",
     "iopub.status.busy": "2024-11-29T08:11:40.791253Z",
     "iopub.status.idle": "2024-11-29T08:11:59.170136Z",
     "shell.execute_reply": "2024-11-29T08:11:59.169442Z",
     "shell.execute_reply.started": "2024-11-29T08:11:40.791487Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "from huggingface_hub.hf_api import HfFolder\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import DefaultDataCollator\n",
    "from transformers import create_optimizer\n",
    "from transformers import TFAutoModelForQuestionAnswering\n",
    "from transformers.keras_callbacks import PushToHubCallback\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T08:12:19.836483Z",
     "iopub.status.busy": "2024-11-29T08:12:19.836118Z",
     "iopub.status.idle": "2024-11-29T08:12:20.027691Z",
     "shell.execute_reply": "2024-11-29T08:12:20.027048Z",
     "shell.execute_reply.started": "2024-11-29T08:12:19.836449Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "user_secrets = UserSecretsClient()\n",
    "hf_token = user_secrets.get_secret(\"HF_TOKEN\")\n",
    "HfFolder.save_token(hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T08:12:20.029213Z",
     "iopub.status.busy": "2024-11-29T08:12:20.028941Z",
     "iopub.status.idle": "2024-11-29T08:12:25.119899Z",
     "shell.execute_reply": "2024-11-29T08:12:25.119273Z",
     "shell.execute_reply.started": "2024-11-29T08:12:20.029187Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "squad = load_dataset(\"squad\", split=\"train[:5000]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T08:12:25.121211Z",
     "iopub.status.busy": "2024-11-29T08:12:25.120945Z",
     "iopub.status.idle": "2024-11-29T08:12:25.140922Z",
     "shell.execute_reply": "2024-11-29T08:12:25.140252Z",
     "shell.execute_reply.started": "2024-11-29T08:12:25.121184Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "squad = squad.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T08:12:25.143863Z",
     "iopub.status.busy": "2024-11-29T08:12:25.143065Z",
     "iopub.status.idle": "2024-11-29T08:12:25.154057Z",
     "shell.execute_reply": "2024-11-29T08:12:25.153327Z",
     "shell.execute_reply.started": "2024-11-29T08:12:25.143832Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "squad[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T08:12:25.155250Z",
     "iopub.status.busy": "2024-11-29T08:12:25.155006Z",
     "iopub.status.idle": "2024-11-29T08:12:26.488256Z",
     "shell.execute_reply": "2024-11-29T08:12:26.487345Z",
     "shell.execute_reply.started": "2024-11-29T08:12:25.155225Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T08:12:26.489564Z",
     "iopub.status.busy": "2024-11-29T08:12:26.489309Z",
     "iopub.status.idle": "2024-11-29T08:12:26.497773Z",
     "shell.execute_reply": "2024-11-29T08:12:26.496867Z",
     "shell.execute_reply.started": "2024-11-29T08:12:26.489538Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=384,\n",
    "        truncation=\"only_second\",\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "    answers = examples[\"answers\"]\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        answer = answers[i]\n",
    "        start_char = answer[\"answer_start\"][0]\n",
    "        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "\n",
    "        # Find the start and end of the context\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "\n",
    "        # If the answer is not fully inside the context, label it (0, 0)\n",
    "        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            # Otherwise it's the start and end token positions\n",
    "            idx = context_start\n",
    "            while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                idx += 1\n",
    "            start_positions.append(idx - 1)\n",
    "\n",
    "            idx = context_end\n",
    "            while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                idx -= 1\n",
    "            end_positions.append(idx + 1)\n",
    "\n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T08:12:26.499063Z",
     "iopub.status.busy": "2024-11-29T08:12:26.498790Z",
     "iopub.status.idle": "2024-11-29T08:12:28.763174Z",
     "shell.execute_reply": "2024-11-29T08:12:28.762474Z",
     "shell.execute_reply.started": "2024-11-29T08:12:26.499031Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenized_squad = squad.map(preprocess_function, batched=True, remove_columns=squad[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T08:12:28.764417Z",
     "iopub.status.busy": "2024-11-29T08:12:28.764117Z",
     "iopub.status.idle": "2024-11-29T08:12:28.768481Z",
     "shell.execute_reply": "2024-11-29T08:12:28.767651Z",
     "shell.execute_reply.started": "2024-11-29T08:12:28.764389Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_collator = DefaultDataCollator(return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T08:12:28.769794Z",
     "iopub.status.busy": "2024-11-29T08:12:28.769529Z",
     "iopub.status.idle": "2024-11-29T08:12:30.474173Z",
     "shell.execute_reply": "2024-11-29T08:12:30.473210Z",
     "shell.execute_reply.started": "2024-11-29T08:12:28.769770Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "num_epochs = 2\n",
    "total_train_steps = (len(tokenized_squad[\"train\"]) // batch_size) * num_epochs\n",
    "optimizer, schedule = create_optimizer(\n",
    "    init_lr=2e-5,\n",
    "    num_warmup_steps=0,\n",
    "    num_train_steps=total_train_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T08:12:30.477794Z",
     "iopub.status.busy": "2024-11-29T08:12:30.477176Z",
     "iopub.status.idle": "2024-11-29T08:12:32.892718Z",
     "shell.execute_reply": "2024-11-29T08:12:32.891995Z",
     "shell.execute_reply.started": "2024-11-29T08:12:30.477763Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = TFAutoModelForQuestionAnswering.from_pretrained(\"distilbert/distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T08:12:32.894221Z",
     "iopub.status.busy": "2024-11-29T08:12:32.893871Z",
     "iopub.status.idle": "2024-11-29T08:12:33.273626Z",
     "shell.execute_reply": "2024-11-29T08:12:33.272684Z",
     "shell.execute_reply.started": "2024-11-29T08:12:32.894180Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tf_train_set = model.prepare_tf_dataset(\n",
    "    tokenized_squad[\"train\"],\n",
    "    shuffle=True,\n",
    "    batch_size=16,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "\n",
    "tf_validation_set = model.prepare_tf_dataset(\n",
    "    tokenized_squad[\"test\"],\n",
    "    shuffle=False,\n",
    "    batch_size=16,\n",
    "    collate_fn=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T08:12:33.275509Z",
     "iopub.status.busy": "2024-11-29T08:12:33.274842Z",
     "iopub.status.idle": "2024-11-29T08:12:33.287971Z",
     "shell.execute_reply": "2024-11-29T08:12:33.287123Z",
     "shell.execute_reply.started": "2024-11-29T08:12:33.275477Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T08:12:33.289331Z",
     "iopub.status.busy": "2024-11-29T08:12:33.289036Z",
     "iopub.status.idle": "2024-11-29T08:12:36.148979Z",
     "shell.execute_reply": "2024-11-29T08:12:36.148327Z",
     "shell.execute_reply.started": "2024-11-29T08:12:33.289269Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "callback = PushToHubCallback(\n",
    "    output_dir=\"qa_model\",\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T08:12:36.150140Z",
     "iopub.status.busy": "2024-11-29T08:12:36.149904Z",
     "iopub.status.idle": "2024-11-29T08:18:56.231503Z",
     "shell.execute_reply": "2024-11-29T08:18:56.230531Z",
     "shell.execute_reply.started": "2024-11-29T08:12:36.150116Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.fit(x=tf_train_set, validation_data=tf_validation_set, epochs=3, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T08:18:56.232812Z",
     "iopub.status.busy": "2024-11-29T08:18:56.232537Z",
     "iopub.status.idle": "2024-11-29T08:18:56.236896Z",
     "shell.execute_reply": "2024-11-29T08:18:56.236125Z",
     "shell.execute_reply.started": "2024-11-29T08:18:56.232786Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "question = \"How many programming languages does BLOOM support?\"\n",
    "context = \"BLOOM has 176 billion parameters and can generate text in 46 languages natural languages and 13 programming languages.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-29T08:18:56.238164Z",
     "iopub.status.busy": "2024-11-29T08:18:56.237949Z",
     "iopub.status.idle": "2024-11-29T08:18:57.325176Z",
     "shell.execute_reply": "2024-11-29T08:18:57.324336Z",
     "shell.execute_reply.started": "2024-11-29T08:18:56.238142Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "question_answerer = pipeline(\"question-answering\", model=\"qa_model\")\n",
    "question_answerer(question=question, context=context)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 374,
     "sourceId": 799923,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
